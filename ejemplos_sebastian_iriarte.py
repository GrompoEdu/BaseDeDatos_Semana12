# -*- coding: utf-8 -*-
"""Ejemplos_Sebastian_Iriarte.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rFcVDEKj1AZmuLQ2s_ul8NL47WvmiZTd
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

#Utilizaremos la transformacion .map(), realizaremos calculos en los elementos del RDD, estos elementos seran elevados al cuadrado.

rdd1 = sc.parallelize([1, 2, 3, 4])

rdd1.map(lambda x: x ** 2).collect()

#Utilizaremos la transformacion .union(), uniremos el RDD original a uno filtrado que se encargara de mostrar los elementos mayores a 2 de los elementos del RDD original.

rdd_or = sc.parallelize([1, 2, 3, 4, 5])
rdd_fil = rdd_or.filter(lambda x: x > 2)


rdd_or.union(rdd_fil).collect()

#Utilizaremos la transformacion .groupByKey(), crearemos un RDD con palabras y contaremos la cantidad de veces que aparecen los elementos manzana, platano y naranja.

rddp = sc.parallelize([("manzana", 1), ("platano", 1), ("manzana", 1), ("naranja", 1), ("platano", 1), ("manzana", 1)])

rddp.groupByKey().mapValues(len).collect()

#Utilizaremos la transformacion .join(), crearemos un RDD de clientes y otro de ventas, estos seran combinados para analizar el rendimiento de las ventas por cliente

# RDD de clientes
RDDC = sc.parallelize([("client1", "Alice"), ("client2", "Bob")])

# RDD de ventas
RDDV= sc.parallelize([("client1", 300), ("client2", 400), ("client1", 150)])

sorted(RDDC.join(RDDV).collect())

#Utilizaremos la accion .reduce(), primero conseguiremos crear un RDD en lo que sus elementos seran sumados, luego haremos una ecuacion en un rdd que contenga elementos elevados al cuadrado y por ultimo se creara un rdd vacio demostrando que si aplicamos reduce en este nos motraria un error.

from operator import add

rdd01 = sc.parallelize([1, 2, 3, 4, 5,6,7,8,9,10]).reduce(add)
print(rdd01)
rdd02 = sc.parallelize((x ** 2 for x in range(10))).map(lambda x: x).cache().reduce(add)
print(rdd02)
rdd03 = sc.parallelize([]).reduce(add)
print(rdd03)

#Utilizaremos la accion .first(), lo que haremos es crear un RDD con registros de los cuales nos mostrara el primer registro, y crearemos otro rdd vacio donde si le aplicamos la accion first nos saldra error.

rddr = sc.parallelize([("Alice", 1), ("Bob", 2), ("Charlie", 3)]).first()
print(rddr)
sc.parallelize([]).first()

#Utilizaremos la accion max, min, crearemos un rdd donde nos mostrara una cantidad de datos y se nos dara el maximo

rdd_metrica = sc.parallelize([70, 85, 60, 95, 80])

rdd_metrica.max().collect()
rdd_metrica.min().collect()