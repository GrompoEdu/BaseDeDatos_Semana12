# -*- coding: utf-8 -*-
"""Ejemplos_Diego_Malasquez.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qeuNLvUDUTzYCM8gpdHf_NdXxwhF9ZFb
"""

#Transfromacion FILTER
"""
Contexto: Mostrar la edad de los empleados mayores a 30 años
Siendo el filter necesario para realizarlo
"""

from pyspark.context import SparkContext

sc = SparkContext('local', 'test')

rdd_edad = sc.parallelize([25, 26, 88, 15, 30, 50, 22, 40])

rdd_edad.collect()

rdd_edad.filter(lambda x: x >30).collect()

#Transfromacion intersection
"""
Contexto: Se quiere contar con empleados para una tarea. Se necesita que ademas de estar disponibles tienen que estar capacitados, para esto usamos el intersection para encontrar los empleados que cumplan con esos requisitos
"""

e_disponibles = sc.parallelize([100, 102, 103, 104, 106])

e_capacitados = sc.parallelize([103, 105, 106, 107, 108])

e_disponibles.intersection(e_capacitados).collect()

#Transformacion reduceBykey
"""
Contexto: En este caso se uso el reduceByKey (add) para saber las asistencias de los estudiantes (3)
"""

from operator import add

rdd_asistencia= sc.parallelize([("Pepe", 1), ("Raul", 1), ("Carlos", 1), ("Carlos", 1), ("Pepe", 1)])

rdd_asistencia.reduceByKey(add).collect()

#Transformacion cogroup

"""
Contexto: En este caso se uso el cogroup hace que se agrupen los rdds y muestren el id, nombre y la calificacion de los estudiantes

"""
rdd_estudiantes = sc.parallelize([  (1, "Jose"),  (2, "Maria"),   (3, "Leonardo")])

rdd_calificaciones = sc.parallelize([(1, 19), (2, 15), (3, 12)])


resultado = rdd_estudiantes.cogroup(rdd_calificaciones)

resultado = [(id_estudiante, (list(nombres), list(calificaciones))) for id_estudiante, (nombres, calificaciones) in resultado.collect()]

print(resultado)

#Accion collect

"""
Contexto: En este caso el colllect muestra las calificaciones de los estudiantes

"""

rdd_calificaciones = sc.parallelize([20, 15, 16, 11, 18])

rdd_calificaciones.collect()

#Accion take

"""
Contexto: En este caso el take (5) muestra los primeros 5 elementos del rdd

"""
rdd_edades = sc.parallelize([25, 30, 45, 20, 35, 40, 28, 50, 23, 38])

rdd_edades.take(5)

#Accion countByKey

"""
Contexto: En este caso el countByKey cuenta el número de veces que cada clave aparece en un RDD de pares clave-valor.

"""

rdd_productos = sc.parallelize([
    ("producto_1", 1),
    ("producto_2", 1),
    ("producto_1", 1),
    ("producto_3", 1),
    ("producto_2", 1),
    ("producto_1", 1)
])

conteo_productos = rdd_productos.countByKey()

resultado_ordenado = sorted(conteo_productos.items())

print(resultado_ordenado)